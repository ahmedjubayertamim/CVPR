{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8693451-5cd2-4449-a980-965e0465d069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\dell\\anaconda3\\envs\\digit_webcam\\lib\\site-packages (12.0.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8bdc28f-858b-44f9-916b-43a720f99624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: 40\n",
      "Valid images: 679\n",
      "Skipped bad/corrupt images: 0\n",
      "Train: 544 | Val: 135\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32768</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,388,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,280</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential_4 (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32768\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m8,388,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │        \u001b[38;5;34m10,280\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,492,392</span> (32.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,492,392\u001b[0m (32.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,492,392</span> (32.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,492,392\u001b[0m (32.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851ms/step - accuracy: 0.0302 - loss: 3.9097 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - accuracy: 0.0276 - loss: 3.7602 - val_accuracy: 0.0593 - val_loss: 3.6118\n",
      "Epoch 2/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924ms/step - accuracy: 0.0809 - loss: 3.5032 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.0882 - loss: 3.4622 - val_accuracy: 0.1037 - val_loss: 3.3057\n",
      "Epoch 3/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895ms/step - accuracy: 0.1599 - loss: 3.1207 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.2077 - loss: 2.9580 - val_accuracy: 0.4667 - val_loss: 2.2160\n",
      "Epoch 4/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885ms/step - accuracy: 0.3382 - loss: 2.2878 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.3548 - loss: 2.2438 - val_accuracy: 0.5778 - val_loss: 1.5926\n",
      "Epoch 5/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910ms/step - accuracy: 0.5455 - loss: 1.5598 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.5533 - loss: 1.5441 - val_accuracy: 0.7111 - val_loss: 1.1557\n",
      "Epoch 6/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900ms/step - accuracy: 0.6144 - loss: 1.3203 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.6324 - loss: 1.2602 - val_accuracy: 0.7185 - val_loss: 1.0599\n",
      "Epoch 7/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881ms/step - accuracy: 0.7064 - loss: 0.9533 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.7132 - loss: 0.9604 - val_accuracy: 0.8222 - val_loss: 0.6783\n",
      "Epoch 8/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881ms/step - accuracy: 0.7439 - loss: 0.8546 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.7684 - loss: 0.7805 - val_accuracy: 0.7852 - val_loss: 0.6510\n",
      "Epoch 9/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922ms/step - accuracy: 0.7810 - loss: 0.7686 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.8033 - loss: 0.6774 - val_accuracy: 0.8000 - val_loss: 0.6033\n",
      "Epoch 10/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903ms/step - accuracy: 0.8081 - loss: 0.5457 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.7941 - loss: 0.5868 - val_accuracy: 0.8519 - val_loss: 0.4972\n",
      "Epoch 11/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - accuracy: 0.8566 - loss: 0.4967 - val_accuracy: 0.7481 - val_loss: 0.6015\n",
      "Epoch 12/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904ms/step - accuracy: 0.8454 - loss: 0.5099 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.8529 - loss: 0.5076 - val_accuracy: 0.9037 - val_loss: 0.4677\n",
      "Epoch 13/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.8621 - loss: 0.4288 - val_accuracy: 0.9037 - val_loss: 0.4992\n",
      "Epoch 14/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.8824 - loss: 0.3760 - val_accuracy: 0.8963 - val_loss: 0.4853\n",
      "Epoch 15/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900ms/step - accuracy: 0.8972 - loss: 0.3277 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.9007 - loss: 0.3219 - val_accuracy: 0.8963 - val_loss: 0.4462\n",
      "Epoch 16/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907ms/step - accuracy: 0.9004 - loss: 0.3291 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.9099 - loss: 0.2894 - val_accuracy: 0.9037 - val_loss: 0.3433\n",
      "Epoch 17/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9265 - loss: 0.2378 - val_accuracy: 0.9185 - val_loss: 0.4459\n",
      "Epoch 18/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.9320 - loss: 0.2401 - val_accuracy: 0.9259 - val_loss: 0.3470\n",
      "Epoch 19/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.9467 - loss: 0.2003 - val_accuracy: 0.9111 - val_loss: 0.4599\n",
      "Epoch 20/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.9338 - loss: 0.1969 - val_accuracy: 0.8889 - val_loss: 0.6690\n",
      "Saved: cnn_face_model.h5 and class_names.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "DATA_DIR = r\"E:\\Download\\CVPRStudentDataset\" \n",
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "SEED = 42\n",
    "VAL_SPLIT = 0.2\n",
    "\n",
    "# only these formats allowed\n",
    "ALLOWED_EXT = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\", \".gif\")\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "\n",
    "def is_valid_image(path: str) -> bool:\n",
    "    \"\"\"Return True if file is a valid readable image.\"\"\"\n",
    "    try:\n",
    "        with Image.open(path) as im:\n",
    "            im.verify()  # quick corruption check\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "# class folders\n",
    "class_names = sorted([\n",
    "    d for d in os.listdir(DATA_DIR)\n",
    "    if os.path.isdir(os.path.join(DATA_DIR, d))\n",
    "])\n",
    "\n",
    "if len(class_names) == 0:\n",
    "    raise RuntimeError(\"No class folders found. Check DATA_DIR path.\")\n",
    "\n",
    "class_to_idx = {c: i for i, c in enumerate(class_names)}\n",
    "\n",
    "all_paths = []\n",
    "all_labels = []\n",
    "bad_files = []\n",
    "\n",
    "for cls in class_names:\n",
    "    folder = os.path.join(DATA_DIR, cls)\n",
    "    for fn in os.listdir(folder):\n",
    "        path = os.path.join(folder, fn)\n",
    "\n",
    "        # skip non-files\n",
    "        if not os.path.isfile(path):\n",
    "            continue\n",
    "\n",
    "        # skip unsupported extensions (thumbs.db, txt, etc.)\n",
    "        if not fn.lower().endswith(ALLOWED_EXT):\n",
    "            continue\n",
    "\n",
    "        # verify image\n",
    "        if is_valid_image(path):\n",
    "            all_paths.append(path)\n",
    "            all_labels.append(class_to_idx[cls])\n",
    "        else:\n",
    "            bad_files.append(path)\n",
    "\n",
    "print(f\"Classes: {len(class_names)}\")\n",
    "print(f\"Valid images: {len(all_paths)}\")\n",
    "print(f\"Skipped bad/corrupt images: {len(bad_files)}\")\n",
    "\n",
    "# Save bad list (so you can delete later if you want)\n",
    "if bad_files:\n",
    "    with open(\"bad_files.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for p in bad_files:\n",
    "            f.write(p + \"\\n\")\n",
    "    print(\"Saved bad file list -> bad_files.txt\")\n",
    "\n",
    "if len(all_paths) == 0:\n",
    "    raise RuntimeError(\"No valid images found after filtering. Check dataset files.\")\n",
    "\n",
    "\n",
    "\n",
    "idx = np.arange(len(all_paths))\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "val_size = int(VAL_SPLIT * len(all_paths))\n",
    "val_idx = idx[:val_size]\n",
    "train_idx = idx[val_size:]\n",
    "\n",
    "train_paths = [all_paths[i] for i in train_idx]\n",
    "train_labels = [all_labels[i] for i in train_idx]\n",
    "val_paths = [all_paths[i] for i in val_idx]\n",
    "val_labels = [all_labels[i] for i in val_idx]\n",
    "\n",
    "print(f\"Train: {len(train_paths)} | Val: {len(val_paths)}\")\n",
    "\n",
    "\n",
    "def load_and_preprocess(path, label):\n",
    "    img_bytes = tf.io.read_file(path)\n",
    "    img = tf.io.decode_image(img_bytes, channels=3, expand_animations=False)\n",
    "    img.set_shape([None, None, 3])\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    return img, label\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
    "train_ds = train_ds.shuffle(2000, seed=SEED, reshuffle_each_iteration=True)\n",
    "train_ds = train_ds.map(load_and_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "train_ds = train_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n",
    "val_ds = val_ds.map(load_and_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "\n",
    "data_aug = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.05),\n",
    "    layers.RandomZoom(0.10),\n",
    "])\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
    "    data_aug,\n",
    "\n",
    "    layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(len(class_names), activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    keras.callbacks.ModelCheckpoint(\"cnn_face_model.h5\", save_best_only=True),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "with open(\"class_names.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for c in class_names:\n",
    "        f.write(c + \"\\n\")\n",
    "\n",
    "print(\"Saved: cnn_face_model.h5 and class_names.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf488df-6d8e-4fd7-89b7-6c89ed51bd5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a3d364c-093a-4a92-b7af-468cfd3d140d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter new student ID (e.g., 22-99999-1):  22-49538-3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPACE = capture, Q = quit\n",
      "Saved: E:\\Download\\CVPRStudentDataset\\22-49538-3\\01.jpg\n",
      "Saved: E:\\Download\\CVPRStudentDataset\\22-49538-3\\02.jpg\n",
      "No face detected. Try again.\n",
      "Saved: E:\\Download\\CVPRStudentDataset\\22-49538-3\\03.jpg\n",
      "Saved: E:\\Download\\CVPRStudentDataset\\22-49538-3\\04.jpg\n",
      "Saved: E:\\Download\\CVPRStudentDataset\\22-49538-3\\05.jpg\n",
      "Saved: E:\\Download\\CVPRStudentDataset\\22-49538-3\\06.jpg\n",
      "Saved: E:\\Download\\CVPRStudentDataset\\22-49538-3\\07.jpg\n",
      "Saved: E:\\Download\\CVPRStudentDataset\\22-49538-3\\08.jpg\n",
      "Saved: E:\\Download\\CVPRStudentDataset\\22-49538-3\\09.jpg\n",
      "Saved: E:\\Download\\CVPRStudentDataset\\22-49538-3\\10.jpg\n",
      "Saved: E:\\Download\\CVPRStudentDataset\\22-49538-3\\11.jpg\n",
      "Saved: E:\\Download\\CVPRStudentDataset\\22-49538-3\\12.jpg\n",
      "No face detected. Try again.\n",
      "No face detected. Try again.\n",
      "Saved: E:\\Download\\CVPRStudentDataset\\22-49538-3\\13.jpg\n",
      "No face detected. Try again.\n",
      "Saved: E:\\Download\\CVPRStudentDataset\\22-49538-3\\14.jpg\n",
      "Saved: E:\\Download\\CVPRStudentDataset\\22-49538-3\\15.jpg\n",
      "No face detected. Try again.\n",
      "Saved: E:\\Download\\CVPRStudentDataset\\22-49538-3\\16.jpg\n",
      "Saved: E:\\Download\\CVPRStudentDataset\\22-49538-3\\17.jpg\n",
      "No face detected. Try again.\n",
      "Saved: E:\\Download\\CVPRStudentDataset\\22-49538-3\\18.jpg\n",
      "No face detected. Try again.\n",
      "Saved: E:\\Download\\CVPRStudentDataset\\22-49538-3\\19.jpg\n",
      "Saved: E:\\Download\\CVPRStudentDataset\\22-49538-3\\20.jpg\n",
      "Registration complete.\n",
      "\n",
      "IMPORTANT: New student added -> retrain model:\n",
      "python 01_train_cnn.py\n"
     ]
    }
   ],
   "source": [
    "import os, cv2\n",
    "\n",
    "DATA_DIR = r\"E:\\Download\\CVPRStudentDataset\"  \n",
    "NUM = 20\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    ")\n",
    "\n",
    "student_id = input(\"Enter new student ID (e.g., 22-99999-1): \").strip()\n",
    "save_dir = os.path.join(DATA_DIR, student_id)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "print(\"SPACE = capture, Q = quit\")\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.2, 5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "\n",
    "    cv2.putText(frame, f\"{student_id} {count}/{NUM}\", (10,30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2)\n",
    "    cv2.imshow(\"Register\", frame)\n",
    "\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k in [ord(\"q\"), ord(\"Q\")]:\n",
    "        break\n",
    "\n",
    "    if k == 32:  # SPACE\n",
    "        if len(faces) == 0:\n",
    "            print(\"No face detected. Try again.\")\n",
    "            continue\n",
    "        (x,y,w,h) = max(faces, key=lambda b: b[2]*b[3])\n",
    "        face = frame[y:y+h, x:x+w]\n",
    "        face = cv2.resize(face, (256,256))\n",
    "\n",
    "        out = os.path.join(save_dir, f\"{count+1:02d}.jpg\")\n",
    "        cv2.imwrite(out, face)\n",
    "        count += 1\n",
    "        print(\"Saved:\", out)\n",
    "\n",
    "        if count >= NUM:\n",
    "            print(\"Registration complete.\")\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"\\nIMPORTANT: New student added -> retrain model:\")\n",
    "print(\"python 01_train_cnn.py\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31323bcf-57fa-44d9-8269-8d80bb9ee1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M = mark, Q = quit\n",
      "Already marked today.\n",
      "Already marked today.\n",
      "Already marked today.\n",
      "Already marked today.\n",
      "Already marked today.\n",
      "Saved report: attendance.csv\n"
     ]
    }
   ],
   "source": [
    "import cv2, numpy as np, pandas as pd\n",
    "from datetime import datetime\n",
    "from tensorflow import keras\n",
    "\n",
    "MODEL_PATH = \"cnn_face_model.h5\"\n",
    "CLASSES_TXT = \"class_names.txt\"\n",
    "ATT_CSV = \"attendance.csv\"\n",
    "CONF = 0.70\n",
    "IMG_SIZE = (128, 128)\n",
    "\n",
    "model = keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "with open(CLASSES_TXT, \"r\", encoding=\"utf-8\") as f:\n",
    "    class_names = [x.strip() for x in f if x.strip()]\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    ")\n",
    "\n",
    "def preprocess(face_bgr):\n",
    "    face = cv2.resize(face_bgr, IMG_SIZE)\n",
    "    face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "    face = face.astype(\"float32\") / 255.0\n",
    "    return np.expand_dims(face, axis=0)\n",
    "\n",
    "def mark(student_id):\n",
    "    now = datetime.now()\n",
    "    row = {\"student_id\": student_id,\n",
    "           \"date\": now.strftime(\"%Y-%m-%d\"),\n",
    "           \"time\": now.strftime(\"%H:%M:%S\")}\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(ATT_CSV)\n",
    "    except FileNotFoundError:\n",
    "        df = pd.DataFrame(columns=[\"student_id\",\"date\",\"time\"])\n",
    "\n",
    "    # one per day\n",
    "    if ((df[\"student_id\"] == student_id) & (df[\"date\"] == row[\"date\"])).any():\n",
    "        return False\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
    "    df.to_csv(ATT_CSV, index=False)\n",
    "    return True\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "last_name, last_conf = \"No face\", 0.0\n",
    "\n",
    "print(\"M = mark, Q = quit\")\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.2, 5)\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        (x,y,w,h) = max(faces, key=lambda b: b[2]*b[3])\n",
    "        face = frame[y:y+h, x:x+w]\n",
    "\n",
    "        probs = model.predict(preprocess(face), verbose=0)[0]\n",
    "        idx = int(np.argmax(probs))\n",
    "        conf = float(probs[idx])\n",
    "\n",
    "        name = class_names[idx] if conf >= CONF else \"Unknown\"\n",
    "        last_name, last_conf = name, conf\n",
    "\n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "\n",
    "    cv2.putText(frame, f\"{last_name} ({last_conf:.2f})\", (10,30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2)\n",
    "    cv2.imshow(\"Attendance\", frame)\n",
    "\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k in [ord(\"q\"), ord(\"Q\")]:\n",
    "        break\n",
    "    if k in [ord(\"m\"), ord(\"M\")]:\n",
    "        if last_name not in [\"Unknown\", \"No face\"]:\n",
    "            ok = mark(last_name)\n",
    "            print(\"Marked!\" if ok else \"Already marked today.\")\n",
    "        else:\n",
    "            print(\"Unknown / No face -> not marked.\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Saved report:\", ATT_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce0bef5-8151-48d6-a96c-53378e155971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bbf365-aeb5-4753-b286-7da91543a3b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e34a6af-4b67-4767-b886-d3f63c29a295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec11a60-494a-4ca2-932a-ebdbd06e3365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b73052d-b95b-490e-a071-fec589f9febc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commands: summary | all | <student_id> | exit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter:  22-48000-3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      date     time\n",
      "2026-01-06 02:00:56\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter:  all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_id       date     time\n",
      "22-48000-3 2026-01-06 02:00:56\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ATT_CSV = \"attendance.csv\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(ATT_CSV)\n",
    "except FileNotFoundError:\n",
    "    print(\"attendance.csv not found. Run 03_mark_attendance.py first.\")\n",
    "    raise SystemExit\n",
    "\n",
    "print(\"Commands: summary | all | <student_id> | exit\")\n",
    "\n",
    "while True:\n",
    "    q = input(\"\\nEnter: \").strip()\n",
    "    if q.lower() in [\"exit\",\"quit\",\"q\"]:\n",
    "        break\n",
    "    if q.lower() == \"all\":\n",
    "        print(df.sort_values([\"date\",\"time\"], ascending=False).to_string(index=False))\n",
    "        continue\n",
    "    if q.lower() == \"summary\":\n",
    "        s = df.groupby(\"student_id\")[\"date\"].nunique().reset_index(name=\"days_present\")\n",
    "        print(s.sort_values(\"days_present\", ascending=False).to_string(index=False))\n",
    "        continue\n",
    "\n",
    "    sub = df[df[\"student_id\"] == q].sort_values([\"date\",\"time\"], ascending=False)\n",
    "    if sub.empty:\n",
    "        print(\"No record found.\")\n",
    "    else:\n",
    "        print(sub[[\"date\",\"time\"]].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9822d2-65a7-4d34-a4c2-71f09b1cf39b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db884512-9224-416d-8423-e01d9880793f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f601f642-6f0c-475f-9606-14e1320ceac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (digit_webcam)",
   "language": "python",
   "name": "digit_webcam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
